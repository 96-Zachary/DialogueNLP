{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import args\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import logging\n",
    "import warnings\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch import cuda\n",
    "from torch.autograd import Variable\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import args\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import logging\n",
    "import warnings\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch import cuda\n",
    "from torch.autograd import Variable\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 | Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "args.add_data_options(parser)\n",
    "args.add_model_options(parser)\n",
    "args.add_train_options(parser)\n",
    "opt = parser.parse_args([])\n",
    "\n",
    "opt.save_path = 'dataset/Douban/model/'\n",
    "opt.online_process_data = True\n",
    "opt.train_src = 'dataset/Douban/train_10m.src'\n",
    "opt.train_tgt = 'dataset/Douban/train_10m.tgt'\n",
    "opt.layers = 1\n",
    "opt.enc_size = 1024\n",
    "opt.word_vec_size = 512\n",
    "opt.dropout = 0.1\n",
    "opt.batch_size = 512\n",
    "opt.beam_size = 3\n",
    "opt.epochs = 20\n",
    "# opt.gpus = [0]\n",
    "opt.learning_rate = 0.003\n",
    "opt.curriculum = 0\n",
    "opt.extra_shuffle = True\n",
    "opt.start_eval_batch = 15000\n",
    "opt.eval_per_batch = 1200\n",
    "opt.seed = 1234\n",
    "opt.cuda_seed = 1234\n",
    "opt.log_interval = 1\n",
    "opt.enc_heads = 16\n",
    "opt.dec_heads = 16\n",
    "opt.log_interval = 1\n",
    "opt.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available() and (not opt.gpus):\n",
    "    print('CUDA ERROR!')\n",
    "\n",
    "if opt.seed > 0:\n",
    "    torch.manual_seed(opt.seed)\n",
    "    random.seed(opt.seed)\n",
    "    np.random.seed(opt.seed)\n",
    "    \n",
    "\n",
    "if opt.gpus:\n",
    "    if opt.cuda_seed > 0:\n",
    "        torch.cuda.manual_seed(opt.cuda_seed)\n",
    "        torch.manual_seed(opt.cuda_seed)\n",
    "        torch.cuda.manual_seed(opt.cuda_seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "    cuda.set_device(opt.gpus[0])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 | Prepare for Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import layer\n",
    "\n",
    "import onlinePreprocess as onlinePreprocess\n",
    "onlinePreprocess.seq_length = opt.max_sent_length\n",
    "onlinePreprocess.shuffle = True if opt.process_shuffle else False\n",
    "\n",
    "from onlinePreprocess import prepare_data_online\n",
    "from layer.Dict import save_dict, load_dict\n",
    "\n",
    "\"\"\"\n",
    "dists = {\n",
    "    'src':\n",
    "    'tgt':\n",
    "}\n",
    "\"\"\"\n",
    "dicts = {}\n",
    "dicts['src'] = load_dict(opt.save_path+'src.pkl')\n",
    "dicts['tgt'] = load_dict(opt.save_path+'tgt.pkl')\n",
    "\n",
    "\"\"\"\n",
    "dataset = {\n",
    "    type = list\n",
    "    'src':\n",
    "    'ins':\n",
    "    'del':\n",
    "    'tgt':\n",
    "}\n",
    "\"\"\"\n",
    "dataset = prepare_data_online(opt.train_src, \n",
    "                              None, \n",
    "                              opt.train_tgt, \n",
    "                              None)\n",
    "trainData = layer.IDDataSet(dataset['train']['src'],\n",
    "                            dataset['train']['ins'],\n",
    "                            dataset['train']['del'],\n",
    "                            dataset['train']['tgt'],\n",
    "                            opt.batch_size, opt.gpus)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 | Model Struture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layer.TransModel import Encoder, Decoder, Transformer\n",
    "\n",
    "enc_src = Encoder(dicts['src'].size(), opt.word_vec_size, opt.layers, opt.enc_heads,\n",
    "                  opt.enc_size, opt.dropout, opt.device)\n",
    "enc_tgt = Encoder(dicts['tgt'].size(), opt.word_vec_size, opt.layers, opt.enc_heads,\n",
    "                  opt.enc_size, opt.dropout, opt.device)\n",
    "dec = Decoder(dicts['tgt'].size(), opt.word_vec_size, opt.layers, opt.dec_heads,\n",
    "              opt.enc_size, opt.dropout, opt.device)\n",
    "generator = nn.Sequential(\n",
    "        nn.Linear(opt.dec_size, dicts['tgt'].size()), \n",
    "        nn.LogSoftmax(dim=-1))\n",
    "\n",
    "model = Transformer(enc_src, enc_tgt, dec, layer.Constants.PAD, layer.Constants.PAD, opt)\n",
    "model.generator = generator\n",
    "\n",
    "# model.load_state_dict(torch.load('TransModel.pt',map_location=torch.device('cpu')))\n",
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "model.apply(initialize_weights)\n",
    "\n",
    "\n",
    "if len(opt.gpus) >= 1:\n",
    "    model.cuda()\n",
    "    generator.cuda()\n",
    "else:\n",
    "    model.cpu()\n",
    "    generator.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 | Train Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = opt.learning_rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "loss_func = nn.CrossEntropyLoss(ignore_index=layer.Constants.PAD)\n",
    "\n",
    "\n",
    "for epoch in range(opt.start_epoch, opt.epochs+1):\n",
    "    # Train Step\n",
    "    model.train()\n",
    "    if opt.extra_shuffle and epoch > opt.curriculum:\n",
    "        trainData.shuffle()\n",
    "    batch_order = torch.randperm(len(trainData))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    num_correct, num_words = 0, 0\n",
    "    total_loss = 0\n",
    "    for i in range(len(trainData)):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch_idx = batch_order[i]\n",
    "        batch = trainData[batch_idx]\n",
    "\n",
    "        keys = batch[0][0].permute(1,0)\n",
    "        guide1 = batch[1][0].permute(1,0)\n",
    "        guide2 = batch[2][0].permute(1,0)\n",
    "        tgt = batch[3][0].permute(1,0)\n",
    "        \n",
    "        g_output = model(keys, guide1, guide2, tgt)\n",
    "        g_target = tgt[:,1:].contiguous().view(-1)\n",
    "        no_pad_idx = g_target.ne(layer.Constants.PAD)\n",
    "\n",
    "        preds = model.generator(g_output.contiguous().view(-1, g_output.shape[-1]))[no_pad_idx]\n",
    "        targets = g_target[no_pad_idx]\n",
    "\n",
    "        loss = loss_func(preds, targets)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        preds = torch.argmax(preds, dim=-1)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        num_correct += preds.eq(targets).sum().item()\n",
    "        num_words += no_pad_idx.sum().item()\n",
    "        \n",
    "        if (i+1) % opt.log_interval == 0:\n",
    "            batch_time = time.time() - start_time\n",
    "            mins, secs = int(batch_time/60), int(batch_time%60)\n",
    "            \n",
    "            \n",
    "            print('| Epoch: {0} | Batch: {1}/{2} | Train_loss: {3:.3f} | Train_acc: {4:.2f}% |'.format(\n",
    "                    epoch, i+1, len(trainData), total_loss/opt.log_interval, 100*num_correct/num_words\n",
    "            ))\n",
    "            print('\\t | Train_time: {0}m {1}s |'.format(mins, secs))\n",
    "            num_correct, num_words = 0, 0\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'TransModel.pt')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Transformer_without_SA.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
